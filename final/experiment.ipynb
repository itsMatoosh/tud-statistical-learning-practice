{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T18:17:18.816201Z",
     "iopub.status.busy": "2025-01-17T18:17:18.815880Z",
     "iopub.status.idle": "2025-01-17T18:17:19.184510Z",
     "shell.execute_reply": "2025-01-17T18:17:19.183594Z",
     "shell.execute_reply.started": "2025-01-17T18:17:18.816175Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/__main__.py\", line 22, in <module>\n",
      "    from pip._internal.cli.main import main as _main\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 11, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
      "    from pip._internal.cli.main_parser import create_main_parser\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
      "    from pip._internal.build_env import get_runnable_pip\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
      "    from pip._internal.cli.spinners import open_spinner\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
      "    from pip._internal.utils.logging import get_indentation\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
      "    from pip._vendor.rich.console import (\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 60, in <module>\n",
      "    from .pretty import Pretty, is_expandable\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/pretty.py\", line 31, in <module>\n",
      "    import attr as _attr_module\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/__init__.py\", line 10, in <module>\n",
      "    from . import converters, exceptions, filters, setters, validators\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/converters.py\", line 10, in <module>\n",
      "    from ._make import NOTHING, Converter, Factory, pipe\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/_make.py\", line 2963, in <module>\n",
      "    class _AndValidator:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/_make.py\", line 1367, in wrap\n",
      "    builder = _ClassBuilder(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/_make.py\", line 670, in __init__\n",
      "    attrs, base_attrs, base_map = _transform_attrs(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/_make.py\", line 470, in _transform_attrs\n",
      "    attrs = [\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/_make.py\", line 471, in <listcomp>\n",
      "    a.evolve(alias=_default_init_alias_for(a.name)) if not a.alias else a\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/_make.py\", line 2471, in evolve\n",
      "    new = copy.copy(self)\n",
      "  File \"/usr/lib/python3.10/copy.py\", line 92, in copy\n",
      "    rv = reductor(4)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/attr/_make.py\", line 2478, in __getstate__\n",
      "    def __getstate__(self):\n",
      "KeyboardInterrupt\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install facenet-pytorch pandas tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T18:17:24.825733Z",
     "iopub.status.busy": "2025-01-17T18:17:24.825405Z",
     "iopub.status.idle": "2025-01-17T18:17:24.831807Z",
     "shell.execute_reply": "2025-01-17T18:17:24.831135Z",
     "shell.execute_reply.started": "2025-01-17T18:17:24.825707Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "import PIL\n",
    "\n",
    "RNG_SEED = 42\n",
    "\n",
    "random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T18:17:30.205641Z",
     "iopub.status.busy": "2025-01-17T18:17:30.205341Z",
     "iopub.status.idle": "2025-01-17T18:17:30.211501Z",
     "shell.execute_reply": "2025-01-17T18:17:30.210752Z",
     "shell.execute_reply.started": "2025-01-17T18:17:30.205618Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders already exist.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create set folder\n",
    "    os.makedirs(f\"{DATA_DIR}/test\")\n",
    "    os.makedirs(f\"{DATA_DIR}/train\")\n",
    "\n",
    "    # create label folders\n",
    "    os.makedirs(f\"{DATA_DIR}/test/face\")\n",
    "    os.makedirs(f\"{DATA_DIR}/test/no_face\")\n",
    "    \n",
    "    os.makedirs(f\"{DATA_DIR}/train/face\")\n",
    "    os.makedirs(f\"{DATA_DIR}/train/no_face\")\n",
    "except:\n",
    "    print(\"Folders already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T22:13:26.677642Z",
     "iopub.status.busy": "2025-01-17T22:13:26.677333Z",
     "iopub.status.idle": "2025-01-17T22:13:51.316020Z",
     "shell.execute_reply": "2025-01-17T22:13:51.315354Z",
     "shell.execute_reply.started": "2025-01-17T22:13:26.677618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "unmoved = [] # this was used to store all images that were to be labeled\n",
    "\n",
    "files = []\n",
    "test_files = []\n",
    "labeled_files = set(labels[\"filename\"].values)\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(DATA_DIR):\n",
    "    files.extend(filenames)\n",
    "    break\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(f\"{DATA_DIR}/test\"):\n",
    "    for dirname in dirnames:\n",
    "        for (dirpath, dirnames, filenames) in os.walk(f\"{DATA_DIR}/test/{dirname}\"):\n",
    "            test_files.extend(filenames)\n",
    "            break\n",
    "    break\n",
    "\n",
    "unmoved = labels[-labels[\"filename\"].isin(test_files)]\n",
    "files = [file for file in files if file not in labeled_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unmoved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.380610Z",
     "iopub.status.idle": "2025-01-17T18:17:19.380871Z",
     "shell.execute_reply": "2025-01-17T18:17:19.380770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, clear_output\n",
    "\n",
    "face_bttn = widgets.Button(description=\"Face\")\n",
    "no_face_bttn = widgets.Button(description=\"No Face\")\n",
    "out = widgets.Output()\n",
    "\n",
    "count = [0]\n",
    "\n",
    "curr_file = ''\n",
    "\n",
    "def face_bttn_clicked(_):\n",
    "    d = {'filename': files[0],\n",
    "                   'label': 'face'}\n",
    "    files.pop(0)\n",
    "    labels.loc[len(labels)] = d\n",
    "\n",
    "    show_widgets()\n",
    "        \n",
    "face_bttn.on_click(face_bttn_clicked)\n",
    "\n",
    "def no_face_clicked(_):\n",
    "    d = {'filename': files[0],\n",
    "                   'label': 'no face'}\n",
    "    files.pop(0)\n",
    "    labels.loc[len(labels)] = d\n",
    "\n",
    "    show_widgets()\n",
    "\n",
    "no_face_bttn.on_click(no_face_clicked)\n",
    "\n",
    "def show_widgets():\n",
    "    clear_output(wait=True)\n",
    "    buttons = widgets.HBox([face_bttn, no_face_bttn])\n",
    "    \n",
    "    image = widgets.Image(\n",
    "        value=Image(filename=f\"/{DATA_DIR}/{files[0]}\").data,\n",
    "        format=\"webp\",\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "    \n",
    "    text = widgets.Text(f\"Total labeled: {len(labels)}\")\n",
    "    \n",
    "    display(widgets.VBox([buttons, text, image, out]))\n",
    "    \n",
    "    \n",
    "# show_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.381590Z",
     "iopub.status.idle": "2025-01-17T18:17:19.381883Z",
     "shell.execute_reply": "2025-01-17T18:17:19.381779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# labels.to_csv(\"new_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T18:18:43.482088Z",
     "iopub.status.busy": "2025-01-17T18:18:43.481786Z",
     "iopub.status.idle": "2025-01-17T18:18:43.493082Z",
     "shell.execute_reply": "2025-01-17T18:18:43.492157Z",
     "shell.execute_reply.started": "2025-01-17T18:18:43.482047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved files to relevant folders\n"
     ]
    }
   ],
   "source": [
    "# This cell was ran separately for both test and train\n",
    "\n",
    "def move_files(row):\n",
    "    filename = row[\"filename\"]\n",
    "    label = row[\"label\"].replace(\" \", \"_\")\n",
    "    \n",
    "    os.rename(f\"data/{filename}\", f\"{DATA_DIR}/train/{label}/{filename}\")\n",
    "\n",
    "faces = unmoved[unmoved[\"label\"] == 'face']\n",
    "no_faces = unmoved[unmoved[\"label\"] == 'no face']\n",
    "\n",
    "try:\n",
    "    faces.apply(move_files, axis=1)\n",
    "    no_faces.apply(move_files, axis=1)\n",
    "    \n",
    "    print(\"Moved files to relevant folders\")\n",
    "except:\n",
    "    print(\"Images are already moved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T18:31:27.517927Z",
     "iopub.status.busy": "2025-01-17T18:31:27.517604Z",
     "iopub.status.idle": "2025-01-17T18:31:34.535632Z",
     "shell.execute_reply": "2025-01-17T18:31:34.534957Z",
     "shell.execute_reply.started": "2025-01-17T18:31:27.517898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "tensor_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), list(labels)\n",
    "\n",
    "dataset_test = datasets.ImageFolder(f\"{DATA_DIR}/test\", transform=transform)\n",
    "dataset_train = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "loader_test = DataLoader(dataset_test, collate_fn=collate_fn, batch_size=8, shuffle=True)\n",
    "loader_train = DataLoader(dataset_train, collate_fn=collate_fn, batch_size=8, shuffle=True,)\n",
    "\n",
    "idx_to_class = {i:c for c, i in dataset_test.class_to_idx.items()}\n",
    "\n",
    "tensor_dataset_test = datasets.ImageFolder(f'{DATA_DIR}/test', transform=tensor_transform)\n",
    "tensor_dataset_train = datasets.ImageFolder(f'{DATA_DIR}/train', transform=tensor_transform)\n",
    "tensor_loader_test = DataLoader(tensor_dataset_test, collate_fn=collate_fn, batch_size=8, shuffle=True)\n",
    "tensor_loader_train = DataLoader(tensor_dataset_train, collate_fn=collate_fn, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define MTCNN baseline\n",
    "We use the default params for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T18:37:27.196843Z",
     "iopub.status.busy": "2025-01-17T18:37:27.196527Z",
     "iopub.status.idle": "2025-01-17T18:37:27.216554Z",
     "shell.execute_reply": "2025-01-17T18:37:27.215858Z",
     "shell.execute_reply.started": "2025-01-17T18:37:27.196819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model with default hyperparameters\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.387074Z",
     "iopub.status.idle": "2025-01-17T18:17:19.387361Z",
     "shell.execute_reply": "2025-01-17T18:17:19.387254Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [04:54<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.077838\n",
      "0.077097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "test_count = 0\n",
    "\n",
    "for X, Y in tqdm(loader_test):\n",
    "    for i in range(0, len(X) - 1):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "\n",
    "        x_aligned, probs = mtcnn.detect(x)\n",
    "\n",
    "        if x_aligned is not None and y == 0:\n",
    "            count += 1\n",
    "\n",
    "            if probs[0] > 0.75:\n",
    "                test_count += 1\n",
    "    \n",
    "print(f\"{(count / len(faces)):8f}\")\n",
    "print(f\"{(test_count / len(faces)):8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T22:12:43.329372Z",
     "iopub.status.busy": "2025-01-17T22:12:43.329034Z",
     "iopub.status.idle": "2025-01-17T22:13:15.591551Z",
     "shell.execute_reply": "2025-01-17T22:13:15.590631Z",
     "shell.execute_reply.started": "2025-01-17T22:12:43.329347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:00<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faulty images so far\n",
      "Found 2 faulty images so far\n",
      "Found 3 faulty images so far\n",
      "Found 4 faulty images so far\n",
      "Found 5 faulty images so far\n",
      "Found 6 faulty images so far\n",
      "Found 7 faulty images so far\n",
      "Found 8 faulty images so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.88it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 1000\n",
    "faulty_img = 0\n",
    "\n",
    "for idx, file in enumerate(tqdm(files)):\n",
    "    img = PIL.Image.open(f\"{DATA_DIR}/{file}\")\n",
    " \n",
    "    try:\n",
    "        # For some reason, there are images with 4 dimensions instead of 3.\n",
    "        # We skip these images and continue with labeling\n",
    "        faces, probs = mtcnn.detect(img)\n",
    "        d = {'filename': file, 'label': 'face' if faces is not None else 'no face'}\n",
    "\n",
    "        labels.loc[len(labels)] = d\n",
    "\n",
    "        if ((idx + 1) % checkpoint) == 0:\n",
    "            print(f\"Saving at {idx + 1}\")\n",
    "            labels.to_csv(\"new_labels.csv\", index=False)\n",
    "    except RuntimeError:\n",
    "        faulty_img += 1\n",
    "        print(f\"Found {faulty_img} faulty images so far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T22:13:19.511111Z",
     "iopub.status.busy": "2025-01-17T22:13:19.510749Z",
     "iopub.status.idle": "2025-01-17T22:13:19.606905Z",
     "shell.execute_reply": "2025-01-17T22:13:19.606198Z",
     "shell.execute_reply.started": "2025-01-17T22:13:19.511050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels.to_csv(\"new_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.392390Z",
     "iopub.status.idle": "2025-01-17T18:17:19.392712Z",
     "shell.execute_reply": "2025-01-17T18:17:19.392547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.393617Z",
     "iopub.status.idle": "2025-01-17T18:17:19.393901Z",
     "shell.execute_reply": "2025-01-17T18:17:19.393792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [02:14<00:00,  9.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# digits = load_digits()\n",
    "X, y = [], []\n",
    "\n",
    "for images, labels in tqdm(tensor_loader_test):\n",
    "    # Flatten images to shape\n",
    "    images_flat = [img.numpy().transpose(1, 2, 0).flatten() for img in images]\n",
    "    X.extend(images_flat)\n",
    "    y.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.394806Z",
     "iopub.status.idle": "2025-01-17T18:17:19.395180Z",
     "shell.execute_reply": "2025-01-17T18:17:19.395018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = np.asarray(y, dtype=int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "gmm_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.395812Z",
     "iopub.status.idle": "2025-01-17T18:17:19.396147Z",
     "shell.execute_reply": "2025-01-17T18:17:19.395968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [09:11<00:00, 275.84s/it]\n"
     ]
    }
   ],
   "source": [
    "for label in tqdm(range(n_classes)):\n",
    "    X_class = X_train[y_train == label]\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=n_classes, covariance_type='full', random_state=42)\n",
    "    gmm.fit(X_class)\n",
    "    gmm_models.append(gmm)\n",
    "\n",
    "# gmm = GaussianMixture(n_components=len(idx_to_class), random_state=42)\n",
    "# gmm.fit(X_train)\n",
    "\n",
    "# # Step 5: Predict Labels\n",
    "# y_pred = gmm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.524 - face and 0.476 - no_face'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, class_counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "f\"{class_counts[0] / len(y_train)} - {idx_to_class[0]} and {class_counts[1] / len(y_train)} - {idx_to_class[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-17T18:17:19.396884Z",
     "iopub.status.idle": "2025-01-17T18:17:19.397210Z",
     "shell.execute_reply": "2025-01-17T18:17:19.397050Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [28:27<00:00,  1.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5518160613128957"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "\n",
    "for sample in tqdm(X_test):\n",
    "    likelihoods = [gmm.score_samples(sample.reshape(1, -1)) for gmm in gmm_models]\n",
    "    \n",
    "    # Assign the class with the highest likelihood\n",
    "    y_pred.append(np.argmax(likelihoods))\n",
    "    \n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6493913,
     "sourceId": 10490262,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
