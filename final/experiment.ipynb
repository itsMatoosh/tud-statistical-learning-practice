{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:22:04.369972Z",
     "start_time": "2025-01-23T05:21:55.224348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: facenet-pytorch in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (1.6.1)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from facenet-pytorch) (2.32.3)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: colorama in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.12.14)\n",
      "Requirement already satisfied: filelock in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\projects\\stat-learning\\final\\.venv\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/39.5 MB 11.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.5/39.5 MB 11.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.8/39.5 MB 11.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 8.4/39.5 MB 10.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 10.7/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/39.5 MB 10.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.2/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.3/39.5 MB 10.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.6/39.5 MB 10.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.2/39.5 MB 10.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 23.6/39.5 MB 10.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.0/39.5 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.3/39.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.7/39.5 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.3/39.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/39.5 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.0/39.5 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/46.2 MB 12.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/46.2 MB 11.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.1/46.2 MB 11.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 9.2/46.2 MB 11.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 11.5/46.2 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.6/46.2 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.7/46.2 MB 11.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 18.1/46.2 MB 11.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.4/46.2 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.5/46.2 MB 11.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 25.2/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.5/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.9/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 32.2/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.6/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.0/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.3/46.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.4/46.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.8/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 11.1 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python, opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.11.0.86 opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install facenet-pytorch pandas tqdm scikit-learn opencv-python opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T04:52:57.052579Z",
     "start_time": "2025-01-23T04:52:57.046722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "RNG_SEED = 42\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Check M1 support\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proccess raw images zip into a usable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders already exist.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create testing folder\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "    # create label folders\n",
    "    os.makedirs(f\"{DATA_DIR}/face\")\n",
    "    os.makedirs(f\"{DATA_DIR}/no_face\")\n",
    "except:\n",
    "    print(\"Folders already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "# Get all image names\n",
    "\n",
    "files = []\n",
    "labeled_files = set(labels[\"filename\"].values)\n",
    "for (dirpath, dirnames, filenames) in os.walk(DATA_DIR):\n",
    "    files.extend(filenames)\n",
    "    break\n",
    "\n",
    "unmoved = labels[labels[\"filename\"].isin(files)]\n",
    "files = [file for file in files if file not in labeled_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, clear_output\n",
    "\n",
    "face_bttn = widgets.Button(description=\"Face\")\n",
    "no_face_bttn = widgets.Button(description=\"No Face\")\n",
    "out = widgets.Output()\n",
    "\n",
    "count = [0]\n",
    "\n",
    "curr_file = ''\n",
    "\n",
    "def face_bttn_clicked(_):\n",
    "    d = {'filename': files[0],\n",
    "                   'label': 'face'}\n",
    "    files.pop(0)\n",
    "    labels.loc[len(labels)] = d\n",
    "\n",
    "    show_widgets()\n",
    "        \n",
    "face_bttn.on_click(face_bttn_clicked)\n",
    "\n",
    "def no_face_clicked(_):\n",
    "    d = {'filename': files[0],\n",
    "                   'label': 'no face'}\n",
    "    files.pop(0)\n",
    "    labels.loc[len(labels)] = d\n",
    "\n",
    "    show_widgets()\n",
    "\n",
    "no_face_bttn.on_click(no_face_clicked)\n",
    "\n",
    "def show_widgets():\n",
    "    clear_output(wait=True)\n",
    "    buttons = widgets.HBox([face_bttn, no_face_bttn])\n",
    "    \n",
    "    image = widgets.Image(\n",
    "        value=Image(filename=f\"/{DATA_DIR}/{files[0]}\").data,\n",
    "        format=\"webp\",\n",
    "        width=300,\n",
    "        height=300\n",
    "    )\n",
    "    \n",
    "    text = widgets.Text(f\"Total labeled: {len(labels)}\")\n",
    "    \n",
    "    display(widgets.VBox([buttons, text, image, out]))\n",
    "    \n",
    "    \n",
    "# show_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved files to relevant folders\n"
     ]
    }
   ],
   "source": [
    "def move_files(row):\n",
    "    filename = row[\"filename\"]\n",
    "    label = row[\"label\"].replace(\" \", \"_\")\n",
    "    \n",
    "    os.rename(f\"data/{filename}\", f\"{data_dir}/{label}/{filename}\")\n",
    "\n",
    "faces = unmoved[unmoved[\"label\"] == 'face']\n",
    "no_faces = unmoved[unmoved[\"label\"] == 'no face']\n",
    "\n",
    "try:\n",
    "    faces.apply(move_files, axis=1)\n",
    "    no_faces.apply(move_files, axis=1)\n",
    "    \n",
    "    print(\"Moved files to relevant folders\")\n",
    "except:\n",
    "    print(\"Images are already moved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "tensor_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), list(labels)\n",
    "\n",
    "base_train = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=transform)\n",
    "base_test = datasets.ImageFolder(f\"{DATA_DIR}/test\", transform=transform)\n",
    "tensor_train = datasets.ImageFolder(f\"{DATA_DIR}/train\", transform=tensor_transform)\n",
    "tensor_test = datasets.ImageFolder(f\"{DATA_DIR}/test\", transform=tensor_transform)\n",
    "\n",
    "base_loader_train = DataLoader(base_train, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "base_loader_test = DataLoader(base_test, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "tensor_loader_train = DataLoader(tensor_train, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "tensor_loader_test = DataLoader(tensor_test, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define MTCNN baseline\n",
    "We use the default params for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T03:57:49.144219Z",
     "start_time": "2025-01-23T03:57:48.987251Z"
    }
   },
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    keep_all=True, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing MTCNN accuracy with manually labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T22:07:59.251191Z",
     "start_time": "2025-01-22T21:45:42.716847Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [10:07<00:00,  2.06it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8097190280971903"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for X, Y in tqdm(base_loader_test):\n",
    "    for i in range(0, len(X)):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "\n",
    "        x_aligned, probs = mtcnn(x, return_prob=True)\n",
    "\n",
    "        y_p = 0 if x_aligned is not None else 1\n",
    "        \n",
    "        y_pred.append(y_p)\n",
    "    y_true.extend(Y)               \n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T00:39:45.714401Z",
     "start_time": "2025-01-23T00:39:45.711069Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(loader):\n",
    "    X = []\n",
    "    y = []\n",
    "    for images, labels in tqdm(loader, desc=\"Flattening data\"):\n",
    "        # Convert images to numpy arrays and flatten\n",
    "        images_flat = [np.array(img).flatten() for img in images]\n",
    "        X.extend(images_flat)\n",
    "        y.extend(labels)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T00:47:47.283427Z",
     "start_time": "2025-01-23T00:39:47.780585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening data: 100%|██████████| 8223/8223 [06:20<00:00, 21.60it/s]\n",
      "Flattening data: 100%|██████████| 2056/2056 [01:37<00:00, 21.16it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preprocess_data(base_loader_train)\n",
    "X_test, y_test = preprocess_data(base_loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-23T00:50:20.643730Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM Model \n",
    "svm_model = svm.SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:53:15.032996Z",
     "start_time": "2025-01-23T07:53:14.932596Z"
    }
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 8\n",
    "# IMG_SIZE = 256\n",
    "# NUM_CLASSES = 2\n",
    "BOVW_CLUSTERS = 500\n",
    "\n",
    "# # We'll do basic transforms: resize + tensor + normalization.\n",
    "# img_transforms = transforms.Compose([\n",
    "#     transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# # Get datasets & loaders\n",
    "# base_train = datasets.ImageFolder(f\"{DATA_DIR}\", transform=img_transforms)\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(base_train, [TRAIN_TEST_SPLIT, 1 - TRAIN_TEST_SPLIT])\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "# test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:53:17.409749Z",
     "start_time": "2025-01-23T07:53:17.407614Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Create SIFT extractor\n",
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:53:19.604948Z",
     "start_time": "2025-01-23T07:53:19.600228Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_to_opencv_img(tensor_img):\n",
    "    \"\"\"\n",
    "    Convert a single image from a PyTorch tensor (C,H,W) to a NumPy array (H,W) or (H,W,3).\n",
    "    We'll convert to grayscale for SIFT.\n",
    "    \"\"\"\n",
    "    # tensor_img shape: (3, H, W) if color\n",
    "    # Move to CPU, convert to numpy\n",
    "    img_np = tensor_img.cpu().numpy()\n",
    "\n",
    "    # img_np shape is (3, H, W). We can convert to (H, W, 3) by transposing\n",
    "    img_np = np.transpose(img_np, (1, 2, 0))  # (H, W, 3)\n",
    "\n",
    "    # Convert to uint8 [0..255] if necessary\n",
    "    img_np = (img_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    return gray\n",
    "\n",
    "def extract_descriptors_from_dataloader(dataloader):\n",
    "    \"\"\"\n",
    "    Loop through an entire DataLoader, extract SIFT descriptors for each image.\n",
    "    \"\"\"\n",
    "    descriptors_per_image = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Assume we already have train_loader that yields (images, labels)\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        # images shape: (batch_size, 3, H, W)\n",
    "        # labels shape: (batch_size,)\n",
    "        \n",
    "        batch_size = len(images)\n",
    "        for i in range(batch_size):\n",
    "            # Convert one image to grayscale OpenCV format\n",
    "            gray_img = tensor_to_opencv_img(images[i])\n",
    "            # Extract SIFT descriptors\n",
    "            kp, desc = sift.detectAndCompute(gray_img, None)\n",
    "            if desc is not None:\n",
    "                descriptors_per_image.append(desc)\n",
    "            else:\n",
    "                # Some images might have no descriptors\n",
    "                descriptors_per_image.append(np.zeros((0,128), dtype=np.float32))\n",
    "\n",
    "            # We also keep the label so we can match it up later\n",
    "            labels_list.append(labels[i])\n",
    "\n",
    "    return descriptors_per_image, labels_list\n",
    "\n",
    "def build_bovw_histogram(descriptors, kmeans_model):\n",
    "    \"\"\"\n",
    "    Given SIFT descriptors (num_keypoints,128) for ONE image,\n",
    "    assign each descriptor to the nearest cluster and build a histogram of size BOVW_CLUSTERS.\n",
    "    \"\"\"\n",
    "    hist = np.zeros((BOVW_CLUSTERS), dtype=np.float32)\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return hist  # no keypoints => zero histogram\n",
    "\n",
    "    words = kmeans_model.predict(descriptors)\n",
    "    for w in words:\n",
    "        hist[w] += 1\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:59:02.924200Z",
     "start_time": "2025-01-23T07:53:25.203785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SIFT descriptors from train_loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9028/9028 [26:24<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected descriptors from 72219 training images.\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting SIFT descriptors from train_loader...\")\n",
    "all_descriptors, all_labels = extract_descriptors_from_dataloader(tensor_loader_train)\n",
    "print(f\"Collected descriptors from {len(all_descriptors)} training images.\")\n",
    "\n",
    "# Stack all descriptors into one large array for K-Means (excluding empty ones)\n",
    "desc_nonempty = [d for d in all_descriptors if d.shape[0] > 0]\n",
    "if len(desc_nonempty) > 0:\n",
    "    all_train_desc = np.vstack(desc_nonempty)\n",
    "else:\n",
    "    all_train_desc = np.zeros((0, 128), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T08:30:54.434707Z",
     "start_time": "2025-01-23T08:00:10.680808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running K-Means on 2736701 descriptors with 500 clusters...\n",
      "Initialization complete\n",
      "Iteration 0, inertia 303670099968.0.\n",
      "Iteration 1, inertia 220359655424.0.\n",
      "Iteration 2, inertia 216534941696.0.\n",
      "Iteration 3, inertia 214825074688.0.\n",
      "Iteration 4, inertia 213802450944.0.\n",
      "Iteration 5, inertia 213118320640.0.\n",
      "Iteration 6, inertia 212629569536.0.\n",
      "Iteration 7, inertia 212261535744.0.\n",
      "Iteration 8, inertia 211970097152.0.\n",
      "Iteration 9, inertia 211737919488.0.\n",
      "Iteration 10, inertia 211544276992.0.\n",
      "Iteration 11, inertia 211383533568.0.\n",
      "Iteration 12, inertia 211243696128.0.\n",
      "Iteration 13, inertia 211125272576.0.\n",
      "Iteration 14, inertia 211022462976.0.\n",
      "Iteration 15, inertia 210932908032.0.\n",
      "Iteration 16, inertia 210853560320.0.\n",
      "Iteration 17, inertia 210782568448.0.\n",
      "Iteration 18, inertia 210719309824.0.\n",
      "Iteration 19, inertia 210663849984.0.\n",
      "Iteration 20, inertia 210610913280.0.\n",
      "Iteration 21, inertia 210561892352.0.\n",
      "Iteration 22, inertia 210514886656.0.\n",
      "Iteration 23, inertia 210471206912.0.\n",
      "Iteration 24, inertia 210428624896.0.\n",
      "Iteration 25, inertia 210390597632.0.\n",
      "Iteration 26, inertia 210354208768.0.\n",
      "Iteration 27, inertia 210320441344.0.\n",
      "Iteration 28, inertia 210288050176.0.\n",
      "Iteration 29, inertia 210258968576.0.\n",
      "Iteration 30, inertia 210230542336.0.\n",
      "Iteration 31, inertia 210204000256.0.\n",
      "Iteration 32, inertia 210179424256.0.\n",
      "Iteration 33, inertia 210155175936.0.\n",
      "Iteration 34, inertia 210132221952.0.\n",
      "Iteration 35, inertia 210111201280.0.\n",
      "Iteration 36, inertia 210091769856.0.\n",
      "Iteration 37, inertia 210072403968.0.\n",
      "Iteration 38, inertia 210054889472.0.\n",
      "Iteration 39, inertia 210039242752.0.\n",
      "Iteration 40, inertia 210024333312.0.\n",
      "Iteration 41, inertia 210009931776.0.\n",
      "Iteration 42, inertia 209997545472.0.\n",
      "Iteration 43, inertia 209984684032.0.\n",
      "Iteration 44, inertia 209972494336.0.\n",
      "Iteration 45, inertia 209961615360.0.\n",
      "Iteration 46, inertia 209950408704.0.\n",
      "Iteration 47, inertia 209939103744.0.\n",
      "Iteration 48, inertia 209929502720.0.\n",
      "Iteration 49, inertia 209919901696.0.\n",
      "Iteration 50, inertia 209910153216.0.\n",
      "Iteration 51, inertia 209901846528.0.\n",
      "Iteration 52, inertia 209893720064.0.\n",
      "Iteration 53, inertia 209885282304.0.\n",
      "Iteration 54, inertia 209878892544.0.\n",
      "Iteration 55, inertia 209873010688.0.\n",
      "Iteration 56, inertia 209866031104.0.\n",
      "Iteration 57, inertia 209858510848.0.\n",
      "Iteration 58, inertia 209851842560.0.\n",
      "Iteration 59, inertia 209846894592.0.\n",
      "Iteration 60, inertia 209841782784.0.\n",
      "Iteration 61, inertia 209836048384.0.\n",
      "Iteration 62, inertia 209830445056.0.\n",
      "Iteration 63, inertia 209824350208.0.\n",
      "Iteration 64, inertia 209819467776.0.\n",
      "Iteration 65, inertia 209814847488.0.\n",
      "Iteration 66, inertia 209810259968.0.\n",
      "Iteration 67, inertia 209805656064.0.\n",
      "Iteration 68, inertia 209801035776.0.\n",
      "Iteration 69, inertia 209796284416.0.\n",
      "Iteration 70, inertia 209792548864.0.\n",
      "Iteration 71, inertia 209787682816.0.\n",
      "Iteration 72, inertia 209783504896.0.\n",
      "Iteration 73, inertia 209779916800.0.\n",
      "Iteration 74, inertia 209776132096.0.\n",
      "Iteration 75, inertia 209772462080.0.\n",
      "Iteration 76, inertia 209769398272.0.\n",
      "Iteration 77, inertia 209766219776.0.\n",
      "Iteration 78, inertia 209764401152.0.\n",
      "Iteration 79, inertia 209761714176.0.\n",
      "Iteration 80, inertia 209758044160.0.\n",
      "Iteration 81, inertia 209755701248.0.\n",
      "Iteration 82, inertia 209752932352.0.\n",
      "Iteration 83, inertia 209749540864.0.\n",
      "Iteration 84, inertia 209746919424.0.\n",
      "Iteration 85, inertia 209744904192.0.\n",
      "Iteration 86, inertia 209742397440.0.\n",
      "Iteration 87, inertia 209740234752.0.\n",
      "Iteration 88, inertia 209737383936.0.\n",
      "Iteration 89, inertia 209735008256.0.\n",
      "Iteration 90, inertia 209732272128.0.\n",
      "Iteration 91, inertia 209729552384.0.\n",
      "Iteration 92, inertia 209727225856.0.\n",
      "Iteration 93, inertia 209725587456.0.\n",
      "Iteration 94, inertia 209723179008.0.\n",
      "Iteration 95, inertia 209720557568.0.\n",
      "Iteration 96, inertia 209718575104.0.\n",
      "Iteration 97, inertia 209716543488.0.\n",
      "Iteration 98, inertia 209714413568.0.\n",
      "Iteration 99, inertia 209711759360.0.\n",
      "Iteration 100, inertia 209709858816.0.\n",
      "Iteration 101, inertia 209708908544.0.\n",
      "Iteration 102, inertia 209707466752.0.\n",
      "Iteration 103, inertia 209705074688.0.\n",
      "Iteration 104, inertia 209703960576.0.\n",
      "Iteration 105, inertia 209702404096.0.\n",
      "Iteration 106, inertia 209700749312.0.\n",
      "Iteration 107, inertia 209699504128.0.\n",
      "Iteration 108, inertia 209697947648.0.\n",
      "Iteration 109, inertia 209696964608.0.\n",
      "Iteration 110, inertia 209695424512.0.\n",
      "Iteration 111, inertia 209693704192.0.\n",
      "Iteration 112, inertia 209692524544.0.\n",
      "Iteration 113, inertia 209691295744.0.\n",
      "Iteration 114, inertia 209690427392.0.\n",
      "Iteration 115, inertia 209689755648.0.\n",
      "Iteration 116, inertia 209688985600.0.\n",
      "Iteration 117, inertia 209688199168.0.\n",
      "Iteration 118, inertia 209687068672.0.\n",
      "Iteration 119, inertia 209685708800.0.\n",
      "Iteration 120, inertia 209684758528.0.\n",
      "Iteration 121, inertia 209684234240.0.\n",
      "Iteration 122, inertia 209682923520.0.\n",
      "Iteration 123, inertia 209681793024.0.\n",
      "Iteration 124, inertia 209681072128.0.\n",
      "Iteration 125, inertia 209679777792.0.\n",
      "Iteration 126, inertia 209678434304.0.\n",
      "Iteration 127, inertia 209677746176.0.\n",
      "Iteration 128, inertia 209677090816.0.\n",
      "Iteration 129, inertia 209676500992.0.\n",
      "Iteration 130, inertia 209675698176.0.\n",
      "Iteration 131, inertia 209675173888.0.\n",
      "Iteration 132, inertia 209674649600.0.\n",
      "Iteration 133, inertia 209673912320.0.\n",
      "Iteration 134, inertia 209673437184.0.\n",
      "Iteration 135, inertia 209672011776.0.\n",
      "Iteration 136, inertia 209671684096.0.\n",
      "Iteration 137, inertia 209670864896.0.\n",
      "Iteration 138, inertia 209670127616.0.\n",
      "Iteration 139, inertia 209669275648.0.\n",
      "Iteration 140, inertia 209667981312.0.\n",
      "Iteration 141, inertia 209667915776.0.\n",
      "Iteration 142, inertia 209667670016.0.\n",
      "Iteration 143, inertia 209666605056.0.\n",
      "Iteration 144, inertia 209665900544.0.\n",
      "Iteration 145, inertia 209665507328.0.\n",
      "Iteration 146, inertia 209664524288.0.\n",
      "Iteration 147, inertia 209664262144.0.\n",
      "Iteration 148, inertia 209663098880.0.\n",
      "Iteration 149, inertia 209662459904.0.\n",
      "Iteration 150, inertia 209661263872.0.\n",
      "Iteration 151, inertia 209659854848.0.\n",
      "Iteration 152, inertia 209659084800.0.\n",
      "Iteration 153, inertia 209658068992.0.\n",
      "Iteration 154, inertia 209658101760.0.\n",
      "Iteration 155, inertia 209657446400.0.\n",
      "Iteration 156, inertia 209656283136.0.\n",
      "Iteration 157, inertia 209655742464.0.\n",
      "Iteration 158, inertia 209654726656.0.\n",
      "Iteration 159, inertia 209654431744.0.\n",
      "Iteration 160, inertia 209654038528.0.\n",
      "Iteration 161, inertia 209653284864.0.\n",
      "Iteration 162, inertia 209652645888.0.\n",
      "Iteration 163, inertia 209652269056.0.\n",
      "Iteration 164, inertia 209651957760.0.\n",
      "Iteration 165, inertia 209651335168.0.\n",
      "Iteration 166, inertia 209650794496.0.\n",
      "Iteration 167, inertia 209650204672.0.\n",
      "Iteration 168, inertia 209649369088.0.\n",
      "Iteration 169, inertia 209648451584.0.\n",
      "Iteration 170, inertia 209647943680.0.\n",
      "Iteration 171, inertia 209647501312.0.\n",
      "Iteration 172, inertia 209646518272.0.\n",
      "Iteration 173, inertia 209646452736.0.\n",
      "Iteration 174, inertia 209645780992.0.\n",
      "Iteration 175, inertia 209644634112.0.\n",
      "Iteration 176, inertia 209644126208.0.\n",
      "Iteration 177, inertia 209643569152.0.\n",
      "Iteration 178, inertia 209642815488.0.\n",
      "Iteration 179, inertia 209642127360.0.\n",
      "Iteration 180, inertia 209641635840.0.\n",
      "Iteration 181, inertia 209641390080.0.\n",
      "Iteration 182, inertia 209640439808.0.\n",
      "Iteration 183, inertia 209639784448.0.\n",
      "Iteration 184, inertia 209639636992.0.\n",
      "Iteration 185, inertia 209638817792.0.\n",
      "Iteration 186, inertia 209638113280.0.\n",
      "Iteration 187, inertia 209637376000.0.\n",
      "Iteration 188, inertia 209637261312.0.\n",
      "Iteration 189, inertia 209636442112.0.\n",
      "Iteration 190, inertia 209636294656.0.\n",
      "Iteration 191, inertia 209635459072.0.\n",
      "Iteration 192, inertia 209634820096.0.\n",
      "Iteration 193, inertia 209634328576.0.\n",
      "Iteration 194, inertia 209633755136.0.\n",
      "Iteration 195, inertia 209633673216.0.\n",
      "Iteration 196, inertia 209632493568.0.\n",
      "Iteration 197, inertia 209632280576.0.\n",
      "Iteration 198, inertia 209631641600.0.\n",
      "Iteration 199, inertia 209631002624.0.\n",
      "Iteration 200, inertia 209630380032.0.\n",
      "Iteration 201, inertia 209630167040.0.\n",
      "Iteration 202, inertia 209629282304.0.\n",
      "Iteration 203, inertia 209628643328.0.\n",
      "Iteration 204, inertia 209627693056.0.\n",
      "Iteration 205, inertia 209627283456.0.\n",
      "Iteration 206, inertia 209626284032.0.\n",
      "Iteration 207, inertia 209626136576.0.\n",
      "Iteration 208, inertia 209625677824.0.\n",
      "Iteration 209, inertia 209625038848.0.\n",
      "Iteration 210, inertia 209624498176.0.\n",
      "Iteration 211, inertia 209624023040.0.\n",
      "Iteration 212, inertia 209623498752.0.\n",
      "Iteration 213, inertia 209623056384.0.\n",
      "Iteration 214, inertia 209622466560.0.\n",
      "Iteration 215, inertia 209622155264.0.\n",
      "Iteration 216, inertia 209621483520.0.\n",
      "Iteration 217, inertia 209620992000.0.\n",
      "Iteration 218, inertia 209620549632.0.\n",
      "Iteration 219, inertia 209620041728.0.\n",
      "Iteration 220, inertia 209619615744.0.\n",
      "Iteration 221, inertia 209618796544.0.\n",
      "Iteration 222, inertia 209618239488.0.\n",
      "Iteration 223, inertia 209617502208.0.\n",
      "Iteration 224, inertia 209617190912.0.\n",
      "Iteration 225, inertia 209617272832.0.\n",
      "Iteration 226, inertia 209616633856.0.\n",
      "Iteration 227, inertia 209616093184.0.\n",
      "Iteration 228, inertia 209615716352.0.\n",
      "Iteration 229, inertia 209615224832.0.\n",
      "Iteration 230, inertia 209614864384.0.\n",
      "Iteration 231, inertia 209613979648.0.\n",
      "Iteration 232, inertia 209613602816.0.\n",
      "Iteration 233, inertia 209612718080.0.\n",
      "Iteration 234, inertia 209612455936.0.\n",
      "Iteration 235, inertia 209612161024.0.\n",
      "Iteration 236, inertia 209612242944.0.\n",
      "Iteration 237, inertia 209611440128.0.\n",
      "Iteration 238, inertia 209611096064.0.\n",
      "Iteration 239, inertia 209610883072.0.\n",
      "Iteration 240, inertia 209610276864.0.\n",
      "Iteration 241, inertia 209609834496.0.\n",
      "Iteration 242, inertia 209609687040.0.\n",
      "Iteration 243, inertia 209609408512.0.\n",
      "Iteration 244, inertia 209608687616.0.\n",
      "Iteration 245, inertia 209608441856.0.\n",
      "Iteration 246, inertia 209607753728.0.\n",
      "Iteration 247, inertia 209607917568.0.\n",
      "Iteration 248, inertia 209607557120.0.\n",
      "Iteration 249, inertia 209607000064.0.\n",
      "Iteration 250, inertia 209606541312.0.\n",
      "Iteration 251, inertia 209605885952.0.\n",
      "Iteration 252, inertia 209605017600.0.\n",
      "Iteration 253, inertia 209604526080.0.\n",
      "Iteration 254, inertia 209603952640.0.\n",
      "Iteration 255, inertia 209603231744.0.\n",
      "Iteration 256, inertia 209602314240.0.\n",
      "Iteration 257, inertia 209601953792.0.\n",
      "Iteration 258, inertia 209601445888.0.\n",
      "Iteration 259, inertia 209600397312.0.\n",
      "Iteration 260, inertia 209598889984.0.\n",
      "Iteration 261, inertia 209597661184.0.\n",
      "Iteration 262, inertia 209597317120.0.\n",
      "Iteration 263, inertia 209596661760.0.\n",
      "Iteration 264, inertia 209596137472.0.\n",
      "Iteration 265, inertia 209595645952.0.\n",
      "Iteration 266, inertia 209595318272.0.\n",
      "Iteration 267, inertia 209594236928.0.\n",
      "Iteration 268, inertia 209593237504.0.\n",
      "Iteration 269, inertia 209592467456.0.\n",
      "Iteration 270, inertia 209591910400.0.\n",
      "Iteration 271, inertia 209591123968.0.\n",
      "Iteration 272, inertia 209590255616.0.\n",
      "Iteration 273, inertia 209589944320.0.\n",
      "Iteration 274, inertia 209589141504.0.\n",
      "Iteration 275, inertia 209588469760.0.\n",
      "Iteration 276, inertia 209587994624.0.\n",
      "Iteration 277, inertia 209587273728.0.\n",
      "Iteration 278, inertia 209586716672.0.\n",
      "Iteration 279, inertia 209586012160.0.\n",
      "Iteration 280, inertia 209585291264.0.\n",
      "Iteration 281, inertia 209584570368.0.\n",
      "Iteration 282, inertia 209583702016.0.\n",
      "Iteration 283, inertia 209582964736.0.\n",
      "Iteration 284, inertia 209582112768.0.\n",
      "Iteration 285, inertia 209581031424.0.\n",
      "Iteration 286, inertia 209580376064.0.\n",
      "Iteration 287, inertia 209580113920.0.\n",
      "Iteration 288, inertia 209579196416.0.\n",
      "Iteration 289, inertia 209578442752.0.\n",
      "Iteration 290, inertia 209578328064.0.\n",
      "Iteration 291, inertia 209577607168.0.\n",
      "Iteration 292, inertia 209577213952.0.\n",
      "Iteration 293, inertia 209576804352.0.\n",
      "Iteration 294, inertia 209576820736.0.\n",
      "Iteration 295, inertia 209576017920.0.\n",
      "Iteration 296, inertia 209575788544.0.\n",
      "Iteration 297, inertia 209575084032.0.\n",
      "Iteration 298, inertia 209574805504.0.\n",
      "Iteration 299, inertia 209574379520.0.\n",
      "K-Means done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if all_train_desc.shape[0] == 0:\n",
    "    print(\"No descriptors found in training set! Can't build K-Means.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Running K-Means on {all_train_desc.shape[0]} descriptors with {BOVW_CLUSTERS} clusters...\")\n",
    "kmeans = KMeans(n_clusters=BOVW_CLUSTERS, random_state=RNG_SEED, verbose=1)\n",
    "kmeans.fit(all_train_desc)\n",
    "print(\"K-Means done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:02:56.536467Z",
     "start_time": "2025-01-23T09:02:02.066014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BoVW histograms for training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72219/72219 [00:25<00:00, 2885.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BoVW shape: (72219, 500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "train_histograms = []\n",
    "train_labels = []\n",
    "\n",
    "idx = 0\n",
    "print(\"Building BoVW histograms for training set...\")\n",
    "for desc in tqdm(all_descriptors):\n",
    "    hist = build_bovw_histogram(desc, kmeans)\n",
    "    train_histograms.append(hist)\n",
    "    train_labels.append(all_labels[idx])\n",
    "    idx += 1\n",
    "\n",
    "train_histograms = np.array(train_histograms, dtype=np.float32)\n",
    "train_labels = np.array(train_labels, dtype=np.int64)\n",
    "\n",
    "# (Optional) Normalize histograms\n",
    "train_histograms = normalize(train_histograms, norm='l2', axis=1)\n",
    "\n",
    "print(\"Train BoVW shape:\", train_histograms.shape)  # (num_train_images, NUM_CLUSTERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:07:46.696297Z",
     "start_time": "2025-01-23T09:07:45.744720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on BoVW histograms...\n",
      "Logistic Regression training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Training Logistic Regression on BoVW histograms...\")\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_histograms, train_labels)\n",
    "print(\"Logistic Regression training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:09:31.605747Z",
     "start_time": "2025-01-23T09:07:50.581495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SIFT descriptors from test_loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1251/1251 [03:23<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BoVW histograms for the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10001/10001 [00:03<00:00, 3058.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test histograms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting SIFT descriptors from test_loader...\")\n",
    "test_descriptors_list, test_labels_list = extract_descriptors_from_dataloader(tensor_loader_test)\n",
    "\n",
    "print(\"Building BoVW histograms for the test set...\")\n",
    "test_histograms = []\n",
    "for desc in tqdm(test_descriptors_list):\n",
    "    hist = build_bovw_histogram(desc, kmeans)\n",
    "    test_histograms.append(hist)\n",
    "\n",
    "test_histograms = np.array(test_histograms, dtype=np.float32)\n",
    "test_histograms = normalize(test_histograms, norm='l2', axis=1)\n",
    "test_labels = np.array(test_labels_list, dtype=np.int64)\n",
    "\n",
    "print(\"Predicting on test histograms...\")\n",
    "test_preds = clf.predict(test_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:09:35.567164Z",
     "start_time": "2025-01-23T09:09:35.560720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 60.41%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Gaussian Mixture model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9028/9028 [25:24<00:00,  5.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# digits = load_digits()\n",
    "X, y = [], []\n",
    "for images, labels in tqdm(tensor_loader_train):\n",
    "    # Flatten images to shape\n",
    "    images_flat = [img.numpy().transpose(1, 2, 0).flatten() for img in images]\n",
    "    X.extend(images_flat)\n",
    "    y.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = np.asarray(y, dtype=int)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_histograms, train_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "gmm_models = []\n",
    "gmm_models_sift = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [01:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     X_class \u001b[38;5;241m=\u001b[39m train_histograms[train_labels \u001b[38;5;241m==\u001b[39m label]\n\u001b[0;32m      4\u001b[0m     gmm \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39mn_classes, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mgmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     gmm_models_sift\u001b[38;5;241m.\u001b[39mappend(gmm)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_classes)):\n",
      "File \u001b[1;32mc:\\Projects\\stat-learning\\final\\.venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:180\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    The fitted mixture.\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Projects\\stat-learning\\final\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Projects\\stat-learning\\final\\.venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:247\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    244\u001b[0m prev_lower_bound \u001b[38;5;241m=\u001b[39m lower_bound\n\u001b[0;32m    246\u001b[0m log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_step(X)\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_resp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n\u001b[0;32m    250\u001b[0m change \u001b[38;5;241m=\u001b[39m lower_bound \u001b[38;5;241m-\u001b[39m prev_lower_bound\n",
      "File \u001b[1;32mc:\\Projects\\stat-learning\\final\\.venv\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:811\u001b[0m, in \u001b[0;36mGaussianMixture._m_step\u001b[1;34m(self, X, log_resp)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_m_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, log_resp):\n\u001b[0;32m    801\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"M step.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[0;32m    803\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m        the point of each sample in X.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 811\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariances_ \u001b[38;5;241m=\u001b[39m \u001b[43m_estimate_gaussian_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_covar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_cholesky_ \u001b[38;5;241m=\u001b[39m _compute_precision_cholesky(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariances_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_type\n\u001b[0;32m    817\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Projects\\stat-learning\\final\\.venv\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:289\u001b[0m, in \u001b[0;36m_estimate_gaussian_parameters\u001b[1;34m(X, resp, reg_covar, covariance_type)\u001b[0m\n\u001b[0;32m    287\u001b[0m nk \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(resp\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39meps\n\u001b[0;32m    288\u001b[0m means \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(resp\u001b[38;5;241m.\u001b[39mT, X) \u001b[38;5;241m/\u001b[39m nk[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m--> 289\u001b[0m covariances \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtied\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_tied\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_diag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspherical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_spherical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcovariance_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nk, means, covariances\n",
      "File \u001b[1;32mc:\\Projects\\stat-learning\\final\\.venv\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:176\u001b[0m, in \u001b[0;36m_estimate_gaussian_covariances_full\u001b[1;34m(resp, X, nk, means, reg_covar)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_components):\n\u001b[0;32m    175\u001b[0m     diff \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m-\u001b[39m means[k]\n\u001b[1;32m--> 176\u001b[0m     covariances[k] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nk[k]\n\u001b[0;32m    177\u001b[0m     covariances[k]\u001b[38;5;241m.\u001b[39mflat[:: n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reg_covar\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m covariances\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training with SIFT\")\n",
    "for label in tqdm(range(n_classes)):\n",
    "    X_class = train_histograms[train_labels == label]\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=n_classes, covariance_type='full', random_state=42)\n",
    "    gmm.fit(X_class)\n",
    "    gmm_models_sift.append(gmm)\n",
    "\n",
    "print(\"Training without SIFT\")\n",
    "for label in tqdm(range(n_classes)):\n",
    "    X_class = X_scaled[y == label]\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=n_classes, covariance_type='full', random_state=42)\n",
    "    gmm.fit(X_class)\n",
    "    gmm_models.append(gmm)\n",
    "\n",
    "\n",
    "\n",
    "# gmm = GaussianMixture(n_components=len(idx_to_class), random_state=42)\n",
    "# gmm.fit(X_train)\n",
    "\n",
    "# # Step 5: Predict Labels\n",
    "# y_pred = gmm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for sample in tqdm(X_test):\n",
    "    likelihoods = gmm.score_samples(sample.reshape(1, -1))\n",
    "    \n",
    "    y_pred.append(np.argmax(likelihoods))\n",
    "    \n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling all images using MTCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/7219 [00:28<2:43:06,  1.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     boxes, probs \u001b[38;5;241m=\u001b[39m \u001b[43mmtcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m boxes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno face\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Append result\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/facenet_pytorch/models/mtcnn.py:313\u001b[0m, in \u001b[0;36mMTCNN.detect\u001b[0;34m(self, img, landmarks)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Detect all faces in PIL image and return bounding boxes and optional facial landmarks.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03mThis method is used by the forward method and is also useful for face detection tasks\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m>>> img_draw.save('annotated_faces.png')\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 313\u001b[0m     batch_boxes, batch_points \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_face\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_face_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthresholds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m boxes, probs, points \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box, point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_boxes, batch_points):\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/facenet_pytorch/models/utils/detect_face.py:73\u001b[0m, in \u001b[0;36mdetect_face\u001b[0;34m(imgs, minsize, pnet, rnet, onet, threshold, factor, device)\u001b[0m\n\u001b[1;32m     71\u001b[0m im_data \u001b[38;5;241m=\u001b[39m imresample(imgs, (\u001b[38;5;28mint\u001b[39m(h \u001b[38;5;241m*\u001b[39m scale \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mint\u001b[39m(w \u001b[38;5;241m*\u001b[39m scale \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     72\u001b[0m im_data \u001b[38;5;241m=\u001b[39m (im_data \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m127.5\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.0078125\u001b[39m\n\u001b[0;32m---> 73\u001b[0m reg, probs \u001b[38;5;241m=\u001b[39m \u001b[43mpnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m boxes_scale, image_inds_scale \u001b[38;5;241m=\u001b[39m generateBoundingBox(reg, probs[:, \u001b[38;5;241m1\u001b[39m], scale, threshold[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     76\u001b[0m boxes\u001b[38;5;241m.\u001b[39mappend(boxes_scale)\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/facenet_pytorch/models/mtcnn.py:43\u001b[0m, in \u001b[0;36mPNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprelu2(x)\n\u001b[0;32m---> 43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprelu3(x)\n\u001b[1;32m     45\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4_1(x)\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "result = []\n",
    "\n",
    "def chunks(lst, batch_size):\n",
    "    for i in range(0, len(lst), batch_size):\n",
    "        yield lst[i:i + batch_size]\n",
    "        \n",
    "data_dir = \"data/\"\n",
    "batch_size = 10\n",
    "all_files = [\n",
    "    os.path.join(root, f)\n",
    "    for root, _, files in os.walk(data_dir)\n",
    "    for f in files if f.endswith(\"webp\")\n",
    "]\n",
    "batches = list(chunks(all_files, batch_size))\n",
    "\n",
    "for batch in tqdm(batches):\n",
    "    for i in range(len(batch)):\n",
    "        if batch[i].endswith(\"webp\"):\n",
    "            image_path = os.path.join(data_dir, batch[i])\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                boxes, probs = mtcnn.detect(img)\n",
    "                \n",
    "                label = \"face\" if boxes is not None else \"no face\"\n",
    "                \n",
    "                # Append result\n",
    "                result.append({\n",
    "                    \"filename\": batch[i],\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error processing {batch[i]}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "output_csv = 'mtcnn_labels.csv'\n",
    "\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"filename\", \"label\"])\n",
    "    writer.writeheader()\n",
    "    for result in result:\n",
    "        writer.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the scaler on smaller chunks of the training data\n",
    "batch_size = 1000  # Adjust based on your available memory\n",
    "for i in tqdm(range(0, len(X_train), batch_size)):\n",
    "    batch = X_train[i:i + batch_size]\n",
    "    scaler.partial_fit(batch)  # Fit incrementally using partial batches\n",
    "\n",
    "# Transform training and test data in chunks\n",
    "def transform_in_batches(data, batch_size, scaler):\n",
    "    transformed_data = []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch = data[i:i + batch_size]\n",
    "        transformed_batch = scaler.transform(batch)\n",
    "        transformed_data.append(transformed_batch)\n",
    "    return np.vstack(transformed_data)\n",
    "\n",
    "X_train_scaled = transform_in_batches(X_train, batch_size, scaler)\n",
    "X_test_scaled = transform_in_batches(X_test, batch_size, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
