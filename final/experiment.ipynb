{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T05:22:04.369972Z",
     "start_time": "2025-01-23T05:21:55.224348Z"
    }
   },
   "source": "%pip install facenet-pytorch pandas tqdm scikit-learn opencv-python opencv-contrib-python",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: pandas in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (1.6.1)\r\n",
      "Requirement already satisfied: opencv-python in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (4.11.0.86)\r\n",
      "Collecting opencv-contrib-python\r\n",
      "  Obtaining dependency information for opencv-contrib-python from https://files.pythonhosted.org/packages/f3/78/b504ca8f7a312918d184e0b8093c62bc9a110d8154f658b591ef5c020d65/opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata\r\n",
      "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from facenet-pytorch) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from facenet-pytorch) (10.2.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from facenet-pytorch) (2.32.3)\r\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from facenet-pytorch) (2.2.2)\r\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from facenet-pytorch) (0.17.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from pandas) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.12.14)\r\n",
      "Requirement already satisfied: filelock in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.12.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/itsmatoosh/Coding/Assignments/Uni/Statistical Learning/tud-statistical-learning-practice/.venv/lib/python3.11/site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\r\n",
      "Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (46.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.3/46.3 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: opencv-contrib-python\r\n",
      "Successfully installed opencv-contrib-python-4.11.0.86\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T04:52:57.052579Z",
     "start_time": "2025-01-23T04:52:57.046722Z"
    }
   },
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "RNG_SEED = 42\n",
    "\n",
    "random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T04:52:15.417753Z",
     "start_time": "2025-01-23T04:52:15.364152Z"
    }
   },
   "source": [
    "# Check M1 support\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Running on device: {}'.format(device))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define MTCNN baseline\n",
    "We use the default params for now"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T03:57:49.144219Z",
     "start_time": "2025-01-23T03:57:48.987251Z"
    }
   },
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    keep_all=True, device=device\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T04:53:44.858164Z",
     "start_time": "2025-01-23T04:53:44.853123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Need to be changed\n",
    "DATA_DIR = \"./data\"\n",
    "TRAIN_TEST_SPLIT = 0.8"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T03:57:50.688129Z",
     "start_time": "2025-01-23T03:57:49.959259Z"
    }
   },
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "tensor_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), list(labels)\n",
    "\n",
    "# Dataset for training\n",
    "dataset = datasets.ImageFolder(f\"{DATA_DIR}\", transform=transform)\n",
    "dataset_train, dataset_test = torch.utils.data.random_split(dataset, [TRAIN_TEST_SPLIT, 1 - TRAIN_TEST_SPLIT])\n",
    "loader_train = DataLoader(dataset_train, collate_fn=collate_fn, batch_size=8, shuffle=True)\n",
    "\n",
    "# Dataset for testing\n",
    "loader_test = DataLoader(dataset_test, collate_fn=collate_fn, batch_size=8, shuffle=True,)\n",
    "tensor_loader = DataLoader(dataset_test, collate_fn=collate_fn, batch_size=8, shuffle=True)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing MTCNN accuracy with manually labelled data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T22:07:59.251191Z",
     "start_time": "2025-01-22T21:45:42.716847Z"
    }
   },
   "source": [
    "count = 0\n",
    "test_count = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "# mtcnn = MTCNN(factor=0.95)\n",
    "\n",
    "for X, Y in tqdm(loader_test):\n",
    "    for i in range(0, len(X)):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "\n",
    "        x_aligned, probs = mtcnn.detect(x)\n",
    "\n",
    "        if x_aligned is not None:\n",
    "            if y == 0:  \n",
    "                count += 1 \n",
    "        else:\n",
    "            if y == 1:  \n",
    "                count += 1 \n",
    "                \n",
    "\n",
    "print(f\"{(count / 10000):8f}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10278/10278 [22:16<00:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.894200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T04:52:34.503800Z",
     "start_time": "2025-01-23T04:52:33.517797Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T00:39:45.714401Z",
     "start_time": "2025-01-23T00:39:45.711069Z"
    }
   },
   "source": [
    "def preprocess_data(loader):\n",
    "    X = []\n",
    "    y = []\n",
    "    for images, labels in tqdm(loader, desc=\"Flattening data\"):\n",
    "        # Convert images to numpy arrays and flatten\n",
    "        images_flat = [np.array(img).flatten() for img in images]\n",
    "        X.extend(images_flat)\n",
    "        y.extend(labels)\n",
    "    return np.array(X), np.array(y)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T00:47:47.283427Z",
     "start_time": "2025-01-23T00:39:47.780585Z"
    }
   },
   "source": [
    "X_train, y_train = preprocess_data(loader_train)\n",
    "X_test, y_test = preprocess_data(loader_test)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening data: 100%|██████████| 8223/8223 [06:20<00:00, 21.60it/s]\n",
      "Flattening data: 100%|██████████| 2056/2056 [01:37<00:00, 21.16it/s]\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-23T00:50:20.643730Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM Model \n",
    "svm_model = svm.SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Logistic Regression"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocess data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:53:15.032996Z",
     "start_time": "2025-01-23T07:53:14.932596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 256\n",
    "NUM_CLASSES = 2\n",
    "BOVW_CLUSTERS = 500\n",
    "\n",
    "# We'll do basic transforms: resize + tensor + normalization.\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Get datasets & loaders\n",
    "dataset = datasets.ImageFolder(f\"{DATA_DIR}\", transform=img_transforms)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [TRAIN_TEST_SPLIT, 1 - TRAIN_TEST_SPLIT])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get SIFT features"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:53:17.409749Z",
     "start_time": "2025-01-23T07:53:17.407614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "# Create SIFT extractor\n",
    "sift = cv2.SIFT_create()"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:53:19.604948Z",
     "start_time": "2025-01-23T07:53:19.600228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tensor_to_opencv_img(tensor_img):\n",
    "    \"\"\"\n",
    "    Convert a single image from a PyTorch tensor (C,H,W) to a NumPy array (H,W) or (H,W,3).\n",
    "    We'll convert to grayscale for SIFT.\n",
    "    \"\"\"\n",
    "    # tensor_img shape: (3, H, W) if color\n",
    "    # Move to CPU, convert to numpy\n",
    "    img_np = tensor_img.cpu().numpy()\n",
    "\n",
    "    # img_np shape is (3, H, W). We can convert to (H, W, 3) by transposing\n",
    "    img_np = np.transpose(img_np, (1, 2, 0))  # (H, W, 3)\n",
    "\n",
    "    # Convert to uint8 [0..255] if necessary\n",
    "    img_np = (img_np * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    return gray\n",
    "\n",
    "def extract_descriptors_from_dataloader(dataloader):\n",
    "    \"\"\"\n",
    "    Loop through an entire DataLoader, extract SIFT descriptors for each image.\n",
    "    \"\"\"\n",
    "    descriptors_per_image = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Assume we already have train_loader that yields (images, labels)\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        # images shape: (batch_size, 3, H, W)\n",
    "        # labels shape: (batch_size,)\n",
    "        batch_size = images.size(0)\n",
    "        for i in range(batch_size):\n",
    "            # Convert one image to grayscale OpenCV format\n",
    "            gray_img = tensor_to_opencv_img(images[i])\n",
    "            # Extract SIFT descriptors\n",
    "            kp, desc = sift.detectAndCompute(gray_img, None)\n",
    "            if desc is not None:\n",
    "                descriptors_per_image.append(desc)\n",
    "            else:\n",
    "                # Some images might have no descriptors\n",
    "                descriptors_per_image.append(np.zeros((0,128), dtype=np.float32))\n",
    "\n",
    "            # We also keep the label so we can match it up later\n",
    "            labels_list.append(labels[i].item())\n",
    "\n",
    "    return descriptors_per_image, labels_list\n",
    "\n",
    "def build_bovw_histogram(descriptors, kmeans_model):\n",
    "    \"\"\"\n",
    "    Given SIFT descriptors (num_keypoints,128) for ONE image,\n",
    "    assign each descriptor to the nearest cluster and build a histogram of size BOVW_CLUSTERS.\n",
    "    \"\"\"\n",
    "    hist = np.zeros((BOVW_CLUSTERS,), dtype=np.float32)\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return hist  # no keypoints => zero histogram\n",
    "\n",
    "    words = kmeans_model.predict(descriptors)\n",
    "    for w in words:\n",
    "        hist[w] += 1\n",
    "\n",
    "    return hist"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T07:59:02.924200Z",
     "start_time": "2025-01-23T07:53:25.203785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Collecting SIFT descriptors from train_loader...\")\n",
    "all_descriptors, all_labels = extract_descriptors_from_dataloader(train_loader)\n",
    "print(f\"Collected descriptors from {len(all_descriptors)} training images.\")\n",
    "\n",
    "# Stack all descriptors into one large array for K-Means (excluding empty ones)\n",
    "desc_nonempty = [d for d in all_descriptors if d.shape[0] > 0]\n",
    "if len(desc_nonempty) > 0:\n",
    "    all_train_desc = np.vstack(desc_nonempty)\n",
    "else:\n",
    "    all_train_desc = np.zeros((0, 128), dtype=np.float32)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SIFT descriptors from train_loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8223 [00:00<?, ?it/s]python(33412) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(33416) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "100%|██████████| 8223/8223 [05:32<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected descriptors from 65777 training images.\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T08:30:54.434707Z",
     "start_time": "2025-01-23T08:00:10.680808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if all_train_desc.shape[0] == 0:\n",
    "    print(\"No descriptors found in training set! Can't build K-Means.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Running K-Means on {all_train_desc.shape[0]} descriptors with {BOVW_CLUSTERS} clusters...\")\n",
    "kmeans = KMeans(n_clusters=BOVW_CLUSTERS, random_state=RNG_SEED, verbose=1)\n",
    "kmeans.fit(all_train_desc)\n",
    "print(\"K-Means done.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running K-Means on 18050453 descriptors with 500 clusters...\n",
      "Initialization complete\n",
      "Iteration 0, inertia 1849718472704.0.\n",
      "Iteration 1, inertia 1344751009792.0.\n",
      "Iteration 2, inertia 1320826961920.0.\n",
      "Iteration 3, inertia 1310717640704.0.\n",
      "Iteration 4, inertia 1304969609216.0.\n",
      "Iteration 5, inertia 1301103771648.0.\n",
      "Iteration 6, inertia 1298242732032.0.\n",
      "Iteration 7, inertia 1295986327552.0.\n",
      "Iteration 8, inertia 1294159314944.0.\n",
      "Iteration 9, inertia 1292659982336.0.\n",
      "Iteration 10, inertia 1291431444480.0.\n",
      "Iteration 11, inertia 1290394271744.0.\n",
      "Iteration 12, inertia 1289526968320.0.\n",
      "Iteration 13, inertia 1288796504064.0.\n",
      "Iteration 14, inertia 1288169717760.0.\n",
      "Iteration 15, inertia 1287635599360.0.\n",
      "Iteration 16, inertia 1287166885888.0.\n",
      "Iteration 17, inertia 1286761611264.0.\n",
      "Iteration 18, inertia 1286393823232.0.\n",
      "Iteration 19, inertia 1286061162496.0.\n",
      "Iteration 20, inertia 1285761269760.0.\n",
      "Iteration 21, inertia 1285486018560.0.\n",
      "Iteration 22, inertia 1285236981760.0.\n",
      "Iteration 23, inertia 1285008654336.0.\n",
      "Iteration 24, inertia 1284793827328.0.\n",
      "Iteration 25, inertia 1284590534656.0.\n",
      "Iteration 26, inertia 1284396023808.0.\n",
      "Iteration 27, inertia 1284226285568.0.\n",
      "Iteration 28, inertia 1284056023040.0.\n",
      "Iteration 29, inertia 1283896770560.0.\n",
      "Iteration 30, inertia 1283751280640.0.\n",
      "Iteration 31, inertia 1283614572544.0.\n",
      "Iteration 32, inertia 1283489529856.0.\n",
      "Iteration 33, inertia 1283385196544.0.\n",
      "Iteration 34, inertia 1283280863232.0.\n",
      "Iteration 35, inertia 1283185442816.0.\n",
      "Iteration 36, inertia 1283094609920.0.\n",
      "Iteration 37, inertia 1283006267392.0.\n",
      "Iteration 38, inertia 1282927230976.0.\n",
      "Iteration 39, inertia 1282854879232.0.\n",
      "Iteration 40, inertia 1282779643904.0.\n",
      "Iteration 41, inertia 1282708078592.0.\n",
      "Iteration 42, inertia 1282644115456.0.\n",
      "Iteration 43, inertia 1282581725184.0.\n",
      "Iteration 44, inertia 1282515402752.0.\n",
      "Iteration 45, inertia 1282454323200.0.\n",
      "Iteration 46, inertia 1282393505792.0.\n",
      "Iteration 47, inertia 1282335309824.0.\n",
      "Iteration 48, inertia 1282275934208.0.\n",
      "Iteration 49, inertia 1282218131456.0.\n",
      "Iteration 50, inertia 1282161115136.0.\n",
      "Iteration 51, inertia 1282104885248.0.\n",
      "Iteration 52, inertia 1282054422528.0.\n",
      "Iteration 53, inertia 1282006712320.0.\n",
      "Iteration 54, inertia 1281959133184.0.\n",
      "Iteration 55, inertia 1281916010496.0.\n",
      "Iteration 56, inertia 1281872625664.0.\n",
      "Iteration 57, inertia 1281831993344.0.\n",
      "Iteration 58, inertia 1281793720320.0.\n",
      "Iteration 59, inertia 1281758461952.0.\n",
      "Iteration 60, inertia 1281727922176.0.\n",
      "Iteration 61, inertia 1281694367744.0.\n",
      "Iteration 62, inertia 1281663434752.0.\n",
      "Iteration 63, inertia 1281630928896.0.\n",
      "Iteration 64, inertia 1281601568768.0.\n",
      "Iteration 65, inertia 1281577189376.0.\n",
      "Iteration 66, inertia 1281547567104.0.\n",
      "Iteration 67, inertia 1281521614848.0.\n",
      "Iteration 68, inertia 1281496449024.0.\n",
      "Iteration 69, inertia 1281468137472.0.\n",
      "Iteration 70, inertia 1281443495936.0.\n",
      "Iteration 71, inertia 1281416757248.0.\n",
      "Iteration 72, inertia 1281393295360.0.\n",
      "Iteration 73, inertia 1281368915968.0.\n",
      "Iteration 74, inertia 1281346895872.0.\n",
      "Iteration 75, inertia 1281324613632.0.\n",
      "Iteration 76, inertia 1281300103168.0.\n",
      "Iteration 77, inertia 1281277296640.0.\n",
      "Iteration 78, inertia 1281249771520.0.\n",
      "Iteration 79, inertia 1281229193216.0.\n",
      "Iteration 80, inertia 1281206124544.0.\n",
      "Iteration 81, inertia 1281175060480.0.\n",
      "Iteration 82, inertia 1281148846080.0.\n",
      "Iteration 83, inertia 1281125253120.0.\n",
      "Iteration 84, inertia 1281100611584.0.\n",
      "Iteration 85, inertia 1281077411840.0.\n",
      "Iteration 86, inertia 1281052377088.0.\n",
      "Iteration 87, inertia 1281029570560.0.\n",
      "Iteration 88, inertia 1281004929024.0.\n",
      "Iteration 89, inertia 1280984350720.0.\n",
      "Iteration 90, inertia 1280960495616.0.\n",
      "Iteration 91, inertia 1280937164800.0.\n",
      "Iteration 92, inertia 1280918945792.0.\n",
      "Iteration 93, inertia 1280893517824.0.\n",
      "Iteration 94, inertia 1280873988096.0.\n",
      "Iteration 95, inertia 1280851968000.0.\n",
      "Iteration 96, inertia 1280833093632.0.\n",
      "Iteration 97, inertia 1280814874624.0.\n",
      "Iteration 98, inertia 1280799014912.0.\n",
      "Iteration 99, inertia 1280777781248.0.\n",
      "Iteration 100, inertia 1280759300096.0.\n",
      "Iteration 101, inertia 1280743309312.0.\n",
      "Iteration 102, inertia 1280727318528.0.\n",
      "Iteration 103, inertia 1280713162752.0.\n",
      "Iteration 104, inertia 1280696123392.0.\n",
      "Iteration 105, inertia 1280684064768.0.\n",
      "Iteration 106, inertia 1280671088640.0.\n",
      "Iteration 107, inertia 1280659423232.0.\n",
      "Iteration 108, inertia 1280646578176.0.\n",
      "Iteration 109, inertia 1280631373824.0.\n",
      "Iteration 110, inertia 1280616955904.0.\n",
      "Iteration 111, inertia 1280604766208.0.\n",
      "Iteration 112, inertia 1280591003648.0.\n",
      "Iteration 113, inertia 1280578813952.0.\n",
      "Iteration 114, inertia 1280567410688.0.\n",
      "Iteration 115, inertia 1280556793856.0.\n",
      "Iteration 116, inertia 1280546308096.0.\n",
      "Iteration 117, inertia 1280535429120.0.\n",
      "Iteration 118, inertia 1280523370496.0.\n",
      "Iteration 119, inertia 1280515768320.0.\n",
      "Iteration 120, inertia 1280506855424.0.\n",
      "Iteration 121, inertia 1280498204672.0.\n",
      "Iteration 122, inertia 1280484442112.0.\n",
      "Iteration 123, inertia 1280470024192.0.\n",
      "Iteration 124, inertia 1280458752000.0.\n",
      "Iteration 125, inertia 1280447348736.0.\n",
      "Iteration 126, inertia 1280442499072.0.\n",
      "Iteration 127, inertia 1280433061888.0.\n",
      "Iteration 128, inertia 1280421134336.0.\n",
      "Iteration 129, inertia 1280411172864.0.\n",
      "Iteration 130, inertia 1280400818176.0.\n",
      "Iteration 131, inertia 1280391249920.0.\n",
      "Iteration 132, inertia 1280384434176.0.\n",
      "Iteration 133, inertia 1280374996992.0.\n",
      "Iteration 134, inertia 1280366870528.0.\n",
      "Iteration 135, inertia 1280354942976.0.\n",
      "Iteration 136, inertia 1280346685440.0.\n",
      "Iteration 137, inertia 1280338821120.0.\n",
      "Iteration 138, inertia 1280326762496.0.\n",
      "Iteration 139, inertia 1280319160320.0.\n",
      "Iteration 140, inertia 1280306839552.0.\n",
      "Iteration 141, inertia 1280299106304.0.\n",
      "Iteration 142, inertia 1280288882688.0.\n",
      "Iteration 143, inertia 1280280231936.0.\n",
      "Iteration 144, inertia 1280270401536.0.\n",
      "Iteration 145, inertia 1280260702208.0.\n",
      "Iteration 146, inertia 1280249036800.0.\n",
      "Iteration 147, inertia 1280241172480.0.\n",
      "Iteration 148, inertia 1280233308160.0.\n",
      "Iteration 149, inertia 1280224526336.0.\n",
      "Iteration 150, inertia 1280217448448.0.\n",
      "Iteration 151, inertia 1280210632704.0.\n",
      "Iteration 152, inertia 1280201064448.0.\n",
      "Iteration 153, inertia 1280192544768.0.\n",
      "Iteration 154, inertia 1280184418304.0.\n",
      "Iteration 155, inertia 1280178388992.0.\n",
      "Iteration 156, inertia 1280173408256.0.\n",
      "Iteration 157, inertia 1280167510016.0.\n",
      "Iteration 158, inertia 1280160563200.0.\n",
      "Iteration 159, inertia 1280154664960.0.\n",
      "Iteration 160, inertia 1280150077440.0.\n",
      "Iteration 161, inertia 1280146538496.0.\n",
      "Iteration 162, inertia 1280141033472.0.\n",
      "Iteration 163, inertia 1280139067392.0.\n",
      "Iteration 164, inertia 1280131465216.0.\n",
      "Iteration 165, inertia 1280127008768.0.\n",
      "Iteration 166, inertia 1280123338752.0.\n",
      "Iteration 167, inertia 1280120586240.0.\n",
      "Iteration 168, inertia 1280115605504.0.\n",
      "Iteration 169, inertia 1280113770496.0.\n",
      "Iteration 170, inertia 1280111280128.0.\n",
      "Iteration 171, inertia 1280105512960.0.\n",
      "Iteration 172, inertia 1280099352576.0.\n",
      "Iteration 173, inertia 1280095289344.0.\n",
      "Iteration 174, inertia 1280092405760.0.\n",
      "Iteration 175, inertia 1280085327872.0.\n",
      "Iteration 176, inertia 1280082706432.0.\n",
      "Iteration 177, inertia 1280080478208.0.\n",
      "Iteration 178, inertia 1280077463552.0.\n",
      "Iteration 179, inertia 1280071565312.0.\n",
      "Iteration 180, inertia 1280070385664.0.\n",
      "Iteration 181, inertia 1280069074944.0.\n",
      "Iteration 182, inertia 1280064618496.0.\n",
      "Iteration 183, inertia 1280061210624.0.\n",
      "Iteration 184, inertia 1280057016320.0.\n",
      "Iteration 185, inertia 1280051773440.0.\n",
      "Iteration 186, inertia 1280045613056.0.\n",
      "Iteration 187, inertia 1280042860544.0.\n",
      "Iteration 188, inertia 1280040108032.0.\n",
      "Iteration 189, inertia 1280036831232.0.\n",
      "Iteration 190, inertia 1280030670848.0.\n",
      "Iteration 191, inertia 1280027918336.0.\n",
      "Iteration 192, inertia 1280023461888.0.\n",
      "Iteration 193, inertia 1280017563648.0.\n",
      "Iteration 194, inertia 1280012451840.0.\n",
      "Iteration 195, inertia 1280005111808.0.\n",
      "Iteration 196, inertia 1280001179648.0.\n",
      "Iteration 197, inertia 1279996198912.0.\n",
      "Iteration 198, inertia 1279992659968.0.\n",
      "Iteration 199, inertia 1279987941376.0.\n",
      "Iteration 200, inertia 1279982567424.0.\n",
      "Iteration 201, inertia 1279981912064.0.\n",
      "Iteration 202, inertia 1279977062400.0.\n",
      "Iteration 203, inertia 1279972868096.0.\n",
      "Iteration 204, inertia 1279966707712.0.\n",
      "Iteration 205, inertia 1279964872704.0.\n",
      "Iteration 206, inertia 1279961858048.0.\n",
      "Iteration 207, inertia 1279958712320.0.\n",
      "Iteration 208, inertia 1279954255872.0.\n",
      "Iteration 209, inertia 1279953469440.0.\n",
      "Iteration 210, inertia 1279949144064.0.\n",
      "Iteration 211, inertia 1279947046912.0.\n",
      "Iteration 212, inertia 1279943507968.0.\n",
      "Iteration 213, inertia 1279941672960.0.\n",
      "Iteration 214, inertia 1279937740800.0.\n",
      "Iteration 215, inertia 1279934464000.0.\n",
      "Iteration 216, inertia 1279932628992.0.\n",
      "Iteration 217, inertia 1279930138624.0.\n",
      "Iteration 218, inertia 1279927255040.0.\n",
      "Iteration 219, inertia 1279926206464.0.\n",
      "Iteration 220, inertia 1279923585024.0.\n",
      "Iteration 221, inertia 1279920832512.0.\n",
      "Iteration 222, inertia 1279917162496.0.\n",
      "Iteration 223, inertia 1279913885696.0.\n",
      "Iteration 224, inertia 1279911526400.0.\n",
      "Iteration 225, inertia 1279907463168.0.\n",
      "Iteration 226, inertia 1279904841728.0.\n",
      "Iteration 227, inertia 1279902613504.0.\n",
      "Iteration 228, inertia 1279898943488.0.\n",
      "Iteration 229, inertia 1279896190976.0.\n",
      "Iteration 230, inertia 1279893438464.0.\n",
      "Iteration 231, inertia 1279893438464.0.\n",
      "Iteration 232, inertia 1279893176320.0.\n",
      "Iteration 233, inertia 1279893176320.0.\n",
      "Iteration 234, inertia 1279890685952.0.\n",
      "Iteration 235, inertia 1279891079168.0.\n",
      "Iteration 236, inertia 1279886622720.0.\n",
      "Iteration 237, inertia 1279883870208.0.\n",
      "Iteration 238, inertia 1279881641984.0.\n",
      "Iteration 239, inertia 1279878627328.0.\n",
      "Iteration 240, inertia 1279877447680.0.\n",
      "Iteration 241, inertia 1279874564096.0.\n",
      "Iteration 242, inertia 1279872466944.0.\n",
      "Iteration 243, inertia 1279870894080.0.\n",
      "Iteration 244, inertia 1279869059072.0.\n",
      "Iteration 245, inertia 1279866568704.0.\n",
      "Iteration 246, inertia 1279865651200.0.\n",
      "Iteration 247, inertia 1279864078336.0.\n",
      "Iteration 248, inertia 1279861719040.0.\n",
      "Iteration 249, inertia 1279859621888.0.\n",
      "Iteration 250, inertia 1279857524736.0.\n",
      "Iteration 251, inertia 1279854510080.0.\n",
      "Iteration 252, inertia 1279853199360.0.\n",
      "Iteration 253, inertia 1279852281856.0.\n",
      "Iteration 254, inertia 1279849267200.0.\n",
      "Iteration 255, inertia 1279848611840.0.\n",
      "Iteration 256, inertia 1279847301120.0.\n",
      "Iteration 257, inertia 1279845859328.0.\n",
      "Iteration 258, inertia 1279845203968.0.\n",
      "Iteration 259, inertia 1279843106816.0.\n",
      "Iteration 260, inertia 1279841271808.0.\n",
      "Iteration 261, inertia 1279839567872.0.\n",
      "Iteration 262, inertia 1279838650368.0.\n",
      "Iteration 263, inertia 1279836815360.0.\n",
      "Iteration 264, inertia 1279836028928.0.\n",
      "Iteration 265, inertia 1279833669632.0.\n",
      "Iteration 266, inertia 1279832621056.0.\n",
      "Iteration 267, inertia 1279832358912.0.\n",
      "Iteration 268, inertia 1279830130688.0.\n",
      "Iteration 269, inertia 1279830130688.0.\n",
      "Iteration 270, inertia 1279829999616.0.\n",
      "Iteration 271, inertia 1279829999616.0.\n",
      "Iteration 272, inertia 1279828426752.0.\n",
      "Iteration 273, inertia 1279825936384.0.\n",
      "Iteration 274, inertia 1279826067456.0.\n",
      "Iteration 275, inertia 1279824625664.0.\n",
      "Iteration 276, inertia 1279824756736.0.\n",
      "Iteration 277, inertia 1279824756736.0.\n",
      "Iteration 278, inertia 1279824363520.0.\n",
      "Iteration 279, inertia 1279823970304.0.\n",
      "Iteration 280, inertia 1279824232448.0.\n",
      "Iteration 281, inertia 1279823183872.0.\n",
      "Iteration 282, inertia 1279822135296.0.\n",
      "Iteration 283, inertia 1279820431360.0.\n",
      "Iteration 284, inertia 1279820038144.0.\n",
      "Iteration 285, inertia 1279818465280.0.\n",
      "Iteration 286, inertia 1279819120640.0.\n",
      "Iteration 287, inertia 1279818596352.0.\n",
      "Iteration 288, inertia 1279817940992.0.\n",
      "Iteration 289, inertia 1279816892416.0.\n",
      "Iteration 290, inertia 1279816105984.0.\n",
      "Iteration 291, inertia 1279814270976.0.\n",
      "Iteration 292, inertia 1279813615616.0.\n",
      "Iteration 293, inertia 1279812567040.0.\n",
      "Iteration 294, inertia 1279809552384.0.\n",
      "Iteration 295, inertia 1279809945600.0.\n",
      "Iteration 296, inertia 1279809945600.0.\n",
      "Iteration 297, inertia 1279808503808.0.\n",
      "Iteration 298, inertia 1279807062016.0.\n",
      "Iteration 299, inertia 1279806144512.0.\n",
      "K-Means done.\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:02:56.536467Z",
     "start_time": "2025-01-23T09:02:02.066014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "train_histograms = []\n",
    "train_labels = []\n",
    "\n",
    "idx = 0\n",
    "print(\"Building BoVW histograms for training set...\")\n",
    "for desc in tqdm(all_descriptors):\n",
    "    hist = build_bovw_histogram(desc, kmeans)\n",
    "    train_histograms.append(hist)\n",
    "    train_labels.append(all_labels[idx])\n",
    "    idx += 1\n",
    "\n",
    "train_histograms = np.array(train_histograms, dtype=np.float32)\n",
    "train_labels = np.array(train_labels, dtype=np.int64)\n",
    "\n",
    "# (Optional) Normalize histograms\n",
    "train_histograms = normalize(train_histograms, norm='l2', axis=1)\n",
    "\n",
    "print(\"Train BoVW shape:\", train_histograms.shape)  # (num_train_images, NUM_CLUSTERS)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BoVW histograms for training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65777/65777 [00:54<00:00, 1212.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BoVW shape: (65777, 500)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define the Logistic Regression Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:07:46.696297Z",
     "start_time": "2025-01-23T09:07:45.744720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Training Logistic Regression on BoVW histograms...\")\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_histograms, train_labels)\n",
    "print(\"Logistic Regression training complete.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on BoVW histograms...\n",
      "Logistic Regression training complete.\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:09:31.605747Z",
     "start_time": "2025-01-23T09:07:50.581495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Extracting SIFT descriptors from test_loader...\")\n",
    "test_descriptors_list, test_labels_list = extract_descriptors_from_dataloader(test_loader)\n",
    "\n",
    "print(\"Building BoVW histograms for the test set...\")\n",
    "test_histograms = []\n",
    "for desc in tqdm(test_descriptors_list):\n",
    "    hist = build_bovw_histogram(desc, kmeans)\n",
    "    test_histograms.append(hist)\n",
    "\n",
    "test_histograms = np.array(test_histograms, dtype=np.float32)\n",
    "test_histograms = normalize(test_histograms, norm='l2', axis=1)\n",
    "test_labels = np.array(test_labels_list, dtype=np.int64)\n",
    "\n",
    "print(\"Predicting on test histograms...\")\n",
    "test_preds = clf.predict(test_histograms)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SIFT descriptors from test_loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2056 [00:00<?, ?it/s]python(33991) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(33995) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "100%|██████████| 2056/2056 [01:33<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BoVW histograms for the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16443/16443 [00:07<00:00, 2184.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test histograms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T09:09:35.567164Z",
     "start_time": "2025-01-23T09:09:35.560720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 70.43%\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Gaussian Mixture model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits = load_digits()\n",
    "X, y = [], []\n",
    "for images, labels in tqdm(tensor_loader):\n",
    "    # Flatten images to shape\n",
    "    images_flat = [img.numpy().transpose(1, 2, 0).flatten() for img in images]\n",
    "    X.extend(images_flat)\n",
    "    y.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = np.asarray(y, dtype=int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "gmm_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in tqdm(range(n_classes)):\n",
    "    X_class = X_train[y_train == label]\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=n_classes, covariance_type='full', random_state=42)\n",
    "    gmm.fit(X_class)\n",
    "    gmm_models.append(gmm)\n",
    "\n",
    "# gmm = GaussianMixture(n_components=len(idx_to_class), random_state=42)\n",
    "# gmm.fit(X_train)\n",
    "\n",
    "# # Step 5: Predict Labels\n",
    "# y_pred = gmm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for sample in tqdm(X_test):\n",
    "    likelihoods = gmm.score_samples(sample.reshape(1, -1))\n",
    "    \n",
    "    y_pred.append(np.argmax(likelihoods))\n",
    "    \n",
    "    \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling all images using MTCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/7219 [00:28<2:43:06,  1.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     19\u001B[0m     img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(image_path)\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m     boxes, probs \u001B[38;5;241m=\u001B[39m \u001B[43mmtcnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     label \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mface\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m boxes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno face\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# Append result\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/facenet_pytorch/models/mtcnn.py:313\u001B[0m, in \u001B[0;36mMTCNN.detect\u001B[0;34m(self, img, landmarks)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Detect all faces in PIL image and return bounding boxes and optional facial landmarks.\u001B[39;00m\n\u001B[1;32m    274\u001B[0m \n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03mThis method is used by the forward method and is also useful for face detection tasks\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m>>> img_draw.save('annotated_faces.png')\u001B[39;00m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 313\u001B[0m     batch_boxes, batch_points \u001B[38;5;241m=\u001B[39m \u001B[43mdetect_face\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin_face_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monet\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthresholds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfactor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m boxes, probs, points \u001B[38;5;241m=\u001B[39m [], [], []\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m box, point \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(batch_boxes, batch_points):\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/facenet_pytorch/models/utils/detect_face.py:73\u001B[0m, in \u001B[0;36mdetect_face\u001B[0;34m(imgs, minsize, pnet, rnet, onet, threshold, factor, device)\u001B[0m\n\u001B[1;32m     71\u001B[0m im_data \u001B[38;5;241m=\u001B[39m imresample(imgs, (\u001B[38;5;28mint\u001B[39m(h \u001B[38;5;241m*\u001B[39m scale \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m), \u001B[38;5;28mint\u001B[39m(w \u001B[38;5;241m*\u001B[39m scale \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)))\n\u001B[1;32m     72\u001B[0m im_data \u001B[38;5;241m=\u001B[39m (im_data \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m127.5\u001B[39m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.0078125\u001B[39m\n\u001B[0;32m---> 73\u001B[0m reg, probs \u001B[38;5;241m=\u001B[39m \u001B[43mpnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m boxes_scale, image_inds_scale \u001B[38;5;241m=\u001B[39m generateBoundingBox(reg, probs[:, \u001B[38;5;241m1\u001B[39m], scale, threshold[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     76\u001B[0m boxes\u001B[38;5;241m.\u001B[39mappend(boxes_scale)\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/facenet_pytorch/models/mtcnn.py:43\u001B[0m, in \u001B[0;36mPNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     41\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x)\n\u001B[1;32m     42\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprelu2(x)\n\u001B[0;32m---> 43\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprelu3(x)\n\u001B[1;32m     45\u001B[0m a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv4_1(x)\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/master_cs/Elements of Statistical Learning/tud-statistical-learning-practice/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "result = []\n",
    "\n",
    "def chunks(lst, batch_size):\n",
    "    for i in range(0, len(lst), batch_size):\n",
    "        yield lst[i:i + batch_size]\n",
    "        \n",
    "data_dir = \"data/\"\n",
    "batch_size = 10\n",
    "all_files = [\n",
    "    os.path.join(root, f)\n",
    "    for root, _, files in os.walk(data_dir)\n",
    "    for f in files if f.endswith(\"webp\")\n",
    "]\n",
    "batches = list(chunks(all_files, batch_size))\n",
    "\n",
    "for batch in tqdm(batches):\n",
    "    for i in range(len(batch)):\n",
    "        if batch[i].endswith(\"webp\"):\n",
    "            image_path = os.path.join(data_dir, batch[i])\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                boxes, probs = mtcnn.detect(img)\n",
    "                \n",
    "                label = \"face\" if boxes is not None else \"no face\"\n",
    "                \n",
    "                # Append result\n",
    "                result.append({\n",
    "                    \"filename\": batch[i],\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error processing {batch[i]}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "output_csv = 'mtcnn_labels.csv'\n",
    "\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"filename\", \"label\"])\n",
    "    writer.writeheader()\n",
    "    for result in result:\n",
    "        writer.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the scaler on smaller chunks of the training data\n",
    "batch_size = 1000  # Adjust based on your available memory\n",
    "for i in tqdm(range(0, len(X_train), batch_size)):\n",
    "    batch = X_train[i:i + batch_size]\n",
    "    scaler.partial_fit(batch)  # Fit incrementally using partial batches\n",
    "\n",
    "# Transform training and test data in chunks\n",
    "def transform_in_batches(data, batch_size, scaler):\n",
    "    transformed_data = []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch = data[i:i + batch_size]\n",
    "        transformed_batch = scaler.transform(batch)\n",
    "        transformed_data.append(transformed_batch)\n",
    "    return np.vstack(transformed_data)\n",
    "\n",
    "X_train_scaled = transform_in_batches(X_train, batch_size, scaler)\n",
    "X_test_scaled = transform_in_batches(X_test, batch_size, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
